\section{Introduction}
Recent research on game strategy agents has flourished in response to the growing demand for intelligent systems capable of playing strategic games either alongside or against human players. 
Reinforcement learning has established itself as a powerful paradigm for training such agents, enabling them to acquire optimal behaviors through interaction with an environment to maximize cumulative rewards over time.
Since \textbf{AlphaGo} \cite{Silver2016} made its debut and stunned the world by defeating a top human player in 2014, its underlying techniques have attracted widespread attention for their adaptability and accurate predictive capabilities. 
Recognizing the potential of reinforcement learning in artificial intelligence, the research community burgeoned rapidly, leading to significant strides in the field. 

Despite the prevalence of comprehensive surveys on reinforcement learning, certain lesser-known games remain underrepresented, leaving challenges unexplored and insufficiently addressed. 
These marginalized environments often suffer from limited accessibility or standardization, yet they offer valuable opportunities for both advancing the field and making it more approachable. 
In particular, such games can serve as practical testbeds that lower the entry barrier for RL newcomers by providing simpler, controlled environments for experimentation. 
Exploring these games not only helps bridge gaps in current research coverage but also fosters broader engagement and understanding of core RL concepts.

\emph{Tetris} is a classic tile-matching puzzle game in which players manipulate falling geometric blocks to form and clear horizontal lines within a confined grid. 
Several studies \cite{algorta2019gametetrismachinelearning, chen2021playing} have demonstrated the success of reinforcement learning in classic \emph{Tetris}, while overlooking its variants.
In this research, we use \emph{2D Tetris} with its classic rules as a benchmark to assess the performance of \textbf{Deep Q-Network (DQN)} \cite{mnih2013playingatarideepreinforcement} across two distinct environments: \emph{2D-Pentominoes-Tetris} and \emph{3D-Cube-Tetris}. 
Through comparative analysis, we aim to elucidate the strengths and limitations of \textbf{DQN}, contributing to a deeper understanding of its applicability across diverse gaming environments.